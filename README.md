

My original idea came from the recent progress in language models. I
wanted to see if we could crowdsource turing tests
in a more controlled environment that could be better used to evaluate
language models. If you really stress a system, you may not be fooled,
but I think it's interesting to see how well a system can fool
people in a more natural setting. I think it will also just be fun for
people to actually try it for themselves and see how they do!

In the future, I think it would be cool if there were a platform for ML
researchers to run experiments like this as models continue to advance.
I could also imagine different experiments could be designed to test
other models, like image models.